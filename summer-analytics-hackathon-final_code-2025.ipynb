{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PC41vTJjU-0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfd3968-9e42-4779-91a7-a8dae0ca1b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (8000, 30)\n",
            "Test shape: (2845, 29)\n",
            "\n",
            "Class distribution:\n",
            "class\n",
            "forest        6159\n",
            "farm           841\n",
            "impervious     669\n",
            "grass          196\n",
            "water          105\n",
            "orchard         30\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remaining missing values in train: 0\n",
            "Remaining missing values in test: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv('/content/hacktrain.csv')\n",
        "test = pd.read_csv('/content/hacktest.csv')\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)\n",
        "print(\"\\nClass distribution:\")\n",
        "print(train['class'].value_counts())\n",
        "\n",
        "# Identify NDVI columns\n",
        "ndvi_cols = [col for col in train.columns if col.endswith('_N')]\n",
        "\n",
        "# Fill missing values with median\n",
        "train[ndvi_cols] = train[ndvi_cols].fillna(train[ndvi_cols].median())\n",
        "test[ndvi_cols] = test[ndvi_cols].fillna(test[ndvi_cols].median())\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(\"\\nRemaining missing values in train:\", train[ndvi_cols].isnull().sum().sum())\n",
        "print(\"Remaining missing values in test:\", test[ndvi_cols].isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_features(df, ndvi_cols):\n",
        "    features = pd.DataFrame()\n",
        "    features['ID'] = df['ID']\n",
        "\n",
        "    # Basic statistics\n",
        "    stats = ['mean', 'std', 'min', 'max', 'median', 'skew', 'kurtosis']\n",
        "    for stat in stats:\n",
        "        features[f'ndvi_{stat}'] = getattr(df[ndvi_cols], stat)(axis=1)\n",
        "\n",
        "    features['ndvi_range'] = features['ndvi_max'] - features['ndvi_min']\n",
        "    features['ndvi_iqr'] = df[ndvi_cols].quantile(0.75, axis=1) - df[ndvi_cols].quantile(0.25, axis=1)\n",
        "\n",
        "    # Polynomial fit coefficients\n",
        "    features['ndvi_trend'] = df[ndvi_cols].apply(lambda x: np.polyfit(range(len(x)), x, 1)[0], axis=1)\n",
        "    features['ndvi_curve'] = df[ndvi_cols].apply(lambda x: np.polyfit(range(len(x)), x, 2)[0], axis=1)\n",
        "\n",
        "    # Seasonal differences and ratios\n",
        "    for i in range(len(ndvi_cols) - 1):\n",
        "        features[f'ndvi_diff_{i}'] = df[ndvi_cols[i+1]] - df[ndvi_cols[i]]\n",
        "        features[f'ndvi_ratio_{i}'] = df[ndvi_cols[i+1]] / (df[ndvi_cols[i]] + 1e-6)\n",
        "\n",
        "    # Rolling statistics (3-month windows)\n",
        "    window_size = 3\n",
        "    for i in range(len(ndvi_cols) - window_size + 1):\n",
        "        window_cols = ndvi_cols[i:i+window_size]\n",
        "        features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
        "        features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
        "\n",
        "    # Fourier transforms (first 3 frequency components)\n",
        "    fft_values = np.abs(np.fft.rfft(df[ndvi_cols], axis=1))\n",
        "    for i in range(1, min(4, fft_values.shape[1])):\n",
        "        features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
        "\n",
        "    # Percentiles\n",
        "    for q in [0.1, 0.25, 0.75, 0.9]:\n",
        "        features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
        "\n",
        "    # Replace inf/nan if any\n",
        "    features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    features.fillna(0, inplace=True)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Generate features\n",
        "X_train = enhanced_features(train, ndvi_cols)\n",
        "X_test = enhanced_features(test, ndvi_cols)\n",
        "y_train = train['class']\n",
        "\n",
        "print(\"\\nGenerated features:\", list(X_train.columns))\n",
        "print(\"Total features (excluding ID):\", len(X_train.columns) - 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0VF6IVBVAno",
        "outputId": "e0edfb3e-6ca4-49d1-ecff-7e3504bcff73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated features: ['ID', 'ndvi_mean', 'ndvi_std', 'ndvi_min', 'ndvi_max', 'ndvi_median', 'ndvi_skew', 'ndvi_kurtosis', 'ndvi_range', 'ndvi_iqr', 'ndvi_trend', 'ndvi_curve', 'ndvi_diff_0', 'ndvi_ratio_0', 'ndvi_diff_1', 'ndvi_ratio_1', 'ndvi_diff_2', 'ndvi_ratio_2', 'ndvi_diff_3', 'ndvi_ratio_3', 'ndvi_diff_4', 'ndvi_ratio_4', 'ndvi_diff_5', 'ndvi_ratio_5', 'ndvi_diff_6', 'ndvi_ratio_6', 'ndvi_diff_7', 'ndvi_ratio_7', 'ndvi_diff_8', 'ndvi_ratio_8', 'ndvi_diff_9', 'ndvi_ratio_9', 'ndvi_diff_10', 'ndvi_ratio_10', 'ndvi_diff_11', 'ndvi_ratio_11', 'ndvi_diff_12', 'ndvi_ratio_12', 'ndvi_diff_13', 'ndvi_ratio_13', 'ndvi_diff_14', 'ndvi_ratio_14', 'ndvi_diff_15', 'ndvi_ratio_15', 'ndvi_diff_16', 'ndvi_ratio_16', 'ndvi_diff_17', 'ndvi_ratio_17', 'ndvi_diff_18', 'ndvi_ratio_18', 'ndvi_diff_19', 'ndvi_ratio_19', 'ndvi_diff_20', 'ndvi_ratio_20', 'ndvi_diff_21', 'ndvi_ratio_21', 'ndvi_diff_22', 'ndvi_ratio_22', 'ndvi_diff_23', 'ndvi_ratio_23', 'ndvi_diff_24', 'ndvi_ratio_24', 'ndvi_diff_25', 'ndvi_ratio_25', 'ndvi_rolling_mean_0', 'ndvi_rolling_std_0', 'ndvi_rolling_mean_1', 'ndvi_rolling_std_1', 'ndvi_rolling_mean_2', 'ndvi_rolling_std_2', 'ndvi_rolling_mean_3', 'ndvi_rolling_std_3', 'ndvi_rolling_mean_4', 'ndvi_rolling_std_4', 'ndvi_rolling_mean_5', 'ndvi_rolling_std_5', 'ndvi_rolling_mean_6', 'ndvi_rolling_std_6', 'ndvi_rolling_mean_7', 'ndvi_rolling_std_7', 'ndvi_rolling_mean_8', 'ndvi_rolling_std_8', 'ndvi_rolling_mean_9', 'ndvi_rolling_std_9', 'ndvi_rolling_mean_10', 'ndvi_rolling_std_10', 'ndvi_rolling_mean_11', 'ndvi_rolling_std_11', 'ndvi_rolling_mean_12', 'ndvi_rolling_std_12', 'ndvi_rolling_mean_13', 'ndvi_rolling_std_13', 'ndvi_rolling_mean_14', 'ndvi_rolling_std_14', 'ndvi_rolling_mean_15', 'ndvi_rolling_std_15', 'ndvi_rolling_mean_16', 'ndvi_rolling_std_16', 'ndvi_rolling_mean_17', 'ndvi_rolling_std_17', 'ndvi_rolling_mean_18', 'ndvi_rolling_std_18', 'ndvi_rolling_mean_19', 'ndvi_rolling_std_19', 'ndvi_rolling_mean_20', 'ndvi_rolling_std_20', 'ndvi_rolling_mean_21', 'ndvi_rolling_std_21', 'ndvi_rolling_mean_22', 'ndvi_rolling_std_22', 'ndvi_rolling_mean_23', 'ndvi_rolling_std_23', 'ndvi_rolling_mean_24', 'ndvi_rolling_std_24', 'ndvi_fft_1', 'ndvi_fft_2', 'ndvi_fft_3', 'ndvi_q10', 'ndvi_q25', 'ndvi_q75', 'ndvi_q90']\n",
            "Total features (excluding ID): 120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_mean_{i}'] = df[window_cols].mean(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_rolling_std_{i}'] = df[window_cols].std(axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_fft_{i}'] = fft_values[:, i]\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n",
            "<ipython-input-3-054c97ae11a2>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features[f'ndvi_q{int(q*100)}'] = df[ndvi_cols].quantile(q=q, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop ID before training\n",
        "X_train_model = X_train.drop(columns=['ID'])\n",
        "X_test_model = X_test.drop(columns=['ID'])\n",
        "\n",
        "# Train-test split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train_model, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
        "\n",
        "# Apply robust scaling\n",
        "scaler = RobustScaler()\n",
        "X_tr_scaled = scaler.fit_transform(X_tr)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test_model)\n"
      ],
      "metadata": {
        "id": "WRdIirvIVCKE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle Class Imbalance using SMOTETomek\n",
        "smt = SMOTETomek(random_state=42)\n",
        "X_resampled, y_resampled = smt.fit_resample(X_tr_scaled, y_tr)\n",
        "print(\"After resampling class distribution:\\n\", pd.Series(y_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Hs_n3gVE9z",
        "outputId": "8ebcd2b9-6258-47df-8ed5-b8e78eb0e2ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After resampling class distribution:\n",
            " class\n",
            "forest        4927\n",
            "farm          4927\n",
            "water         4927\n",
            "impervious    4927\n",
            "grass         4927\n",
            "orchard       4927\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Logistic Regression Model and Evaluate\n",
        "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "y_pred = clf.predict(X_val_scaled)\n",
        "\n",
        "print(\"\\nValidation Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "1z5QwwUsVHAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108f524b-bdc7-4d3d-c87b-bead5ee221cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.64      0.79      0.71       168\n",
            "      forest       0.98      0.88      0.92      1232\n",
            "       grass       0.37      0.67      0.48        39\n",
            "  impervious       0.77      0.81      0.79       134\n",
            "     orchard       0.11      0.83      0.19         6\n",
            "       water       0.41      0.57      0.48        21\n",
            "\n",
            "    accuracy                           0.85      1600\n",
            "   macro avg       0.55      0.76      0.60      1600\n",
            "weighted avg       0.90      0.85      0.87      1600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation and Feature Selection with RFECV\n",
        "selector = RFECV(clf, step=5, cv=3, scoring='f1_macro', n_jobs=-1)\n",
        "selector = selector.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(\"\\nOptimal number of features:\", selector.n_features_)\n",
        "print(\"Selected features mask:\", selector.support_)\n"
      ],
      "metadata": {
        "id": "CO2jDcUgVJl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8244b9-8101-4f24-c83e-425d1ab92810"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal number of features: 115\n",
            "Selected features mask: [ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True  True  True  True  True  True  True\n",
            " False  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True False  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the resampled training data with the selector\n",
        "X_resampled_selected = selector.transform(X_resampled)\n",
        "\n",
        "# Retrain the classifier on selected features only\n",
        "clf_selected = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "clf_selected.fit(X_resampled_selected, y_resampled)\n",
        "\n",
        "# Transform the test data with the selector\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Predict using the retrained classifier\n",
        "final_predictions = clf_selected.predict(X_test_selected)\n",
        "\n",
        "# Save to submission format\n",
        "submission = pd.DataFrame({'ID': X_test['ID'], 'class': final_predictions})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file saved as 'submission.csv'\")\n"
      ],
      "metadata": {
        "id": "XLhLSv41ia-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e1d9e5-4f5b-4648-b049-3871873279a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved as 'submission.csv'\n"
          ]
        }
      ]
    }
  ]
}